2026-01-16 16:40:37.760 | WARNING: Using incubator modules: jdk.incubator.vector
2026-01-16 16:40:38.829 | Files local:///app/repo/k3s/spark/main.py from /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/main.py to /opt/spark/work-dir/main.py
2026-01-16 16:40:38.893 | 26/01/16 22:40:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2026-01-16 16:40:39.601 | 2026-01-16 22:40:39,600 - SparkPreprocessing - DEBUG - Parameters retrieved from /app/repo/k3s/params.yaml
2026-01-16 16:40:40.130 | 2026-01-16 22:40:40,129 - SparkPreprocessing - INFO - Minio connection verified. Buckets: ['frontend-crm-bucket', 'k8s-mlops-platform-bucket']
2026-01-16 16:40:40.130 | 2026-01-16 22:40:40,130 - SparkPreprocessing - INFO - Creating SparkSession with S3A (MinIO) support
2026-01-16 16:40:40.367 | Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
2026-01-16 16:40:40.370 | 26/01/16 22:40:40 INFO SparkContext: Running Spark version 4.0.1
2026-01-16 16:40:40.372 | 26/01/16 22:40:40 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
2026-01-16 16:40:40.372 | 26/01/16 22:40:40 INFO SparkContext: Java version 17.0.17
2026-01-16 16:40:40.395 | 26/01/16 22:40:40 INFO ResourceUtils: ==============================================================
2026-01-16 16:40:40.395 | 26/01/16 22:40:40 INFO ResourceUtils: No custom resources configured for spark.driver.
2026-01-16 16:40:40.395 | 26/01/16 22:40:40 INFO ResourceUtils: ==============================================================
2026-01-16 16:40:40.397 | 26/01/16 22:40:40 INFO SparkContext: Submitted application: spark-preprocessing
2026-01-16 16:40:40.412 | 26/01/16 22:40:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2026-01-16 16:40:40.417 | 26/01/16 22:40:40 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2026-01-16 16:40:40.419 | 26/01/16 22:40:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
2026-01-16 16:40:40.460 | 26/01/16 22:40:40 INFO SecurityManager: Changing view acls to: spark
2026-01-16 16:40:40.461 | 26/01/16 22:40:40 INFO SecurityManager: Changing modify acls to: spark
2026-01-16 16:40:40.461 | 26/01/16 22:40:40 INFO SecurityManager: Changing view acls groups to: spark
2026-01-16 16:40:40.461 | 26/01/16 22:40:40 INFO SecurityManager: Changing modify acls groups to: spark
2026-01-16 16:40:40.463 | 26/01/16 22:40:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
2026-01-16 16:40:40.618 | 26/01/16 22:40:40 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
2026-01-16 16:40:40.640 | 26/01/16 22:40:40 INFO SparkEnv: Registering MapOutputTracker
2026-01-16 16:40:40.649 | 26/01/16 22:40:40 INFO SparkEnv: Registering BlockManagerMaster
2026-01-16 16:40:40.663 | 26/01/16 22:40:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2026-01-16 16:40:40.663 | 26/01/16 22:40:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2026-01-16 16:40:40.667 | 26/01/16 22:40:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2026-01-16 16:40:40.684 | 26/01/16 22:40:40 INFO DiskBlockManager: Created local directory at /var/data/spark-5e15ccd3-1786-4cf2-8a2a-c880f839b9bd/blockmgr-5715b3ed-0615-4d58-a0b4-44eb25453f65
2026-01-16 16:40:40.702 | 26/01/16 22:40:40 INFO SparkEnv: Registering OutputCommitCoordinator
2026-01-16 16:40:40.803 | 26/01/16 22:40:40 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2026-01-16 16:40:40.879 | 26/01/16 22:40:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2026-01-16 16:40:40.910 | 26/01/16 22:40:40 WARN SparkContext: File with 'local' scheme local:/app/repo/k3s/spark/main.py is not supported to add to file server, since it is already available on every node.
2026-01-16 16:40:40.929 | 26/01/16 22:40:40 INFO SecurityManager: Changing view acls to: spark
2026-01-16 16:40:40.929 | 26/01/16 22:40:40 INFO SecurityManager: Changing modify acls to: spark
2026-01-16 16:40:40.929 | 26/01/16 22:40:40 INFO SecurityManager: Changing view acls groups to: spark
2026-01-16 16:40:40.930 | 26/01/16 22:40:40 INFO SecurityManager: Changing modify acls groups to: spark
2026-01-16 16:40:40.931 | 26/01/16 22:40:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
2026-01-16 16:40:40.975 | 26/01/16 22:40:40 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
2026-01-16 16:40:42.136 | 26/01/16 22:40:42 INFO ExecutorPodsAllocator: Going to request 2 executors from Kubernetes for ResourceProfile Id: 0, target: 2, known: 0, sharedSlotFromPendingPods: 2147483647.
2026-01-16 16:40:42.186 | 26/01/16 22:40:42 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
2026-01-16 16:40:42.367 | 26/01/16 22:40:42 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
2026-01-16 16:40:42.411 | 26/01/16 22:40:42 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
2026-01-16 16:40:42.412 | 26/01/16 22:40:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
2026-01-16 16:40:42.417 | 26/01/16 22:40:42 INFO NettyBlockTransferService: Server created on spark-app-0-driver-svc.spark.svc 10.1.4.100:7079
2026-01-16 16:40:42.419 | 26/01/16 22:40:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2026-01-16 16:40:42.420 | 26/01/16 22:40:42 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
2026-01-16 16:40:42.433 | 26/01/16 22:40:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-app-0-driver-svc.spark.svc, 7079, None)
2026-01-16 16:40:42.439 | 26/01/16 22:40:42 INFO BlockManagerMasterEndpoint: Registering block manager spark-app-0-driver-svc.spark.svc:7079 with 413.9 MiB RAM, BlockManagerId(driver, spark-app-0-driver-svc.spark.svc, 7079, None)
2026-01-16 16:40:42.442 | 26/01/16 22:40:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-app-0-driver-svc.spark.svc, 7079, None)
2026-01-16 16:40:42.443 | 26/01/16 22:40:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-app-0-driver-svc.spark.svc, 7079, None)
2026-01-16 16:40:42.502 | 26/01/16 22:40:42 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
2026-01-16 16:40:42.505 | 26/01/16 22:40:42 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
2026-01-16 16:40:48.102 | 26/01/16 22:40:48 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.4.101:39260) with ID 1, ResourceProfileId 0
2026-01-16 16:40:48.113 | 26/01/16 22:40:48 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.1.4.102:49030) with ID 2, ResourceProfileId 0
2026-01-16 16:40:48.160 | 26/01/16 22:40:48 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2026-01-16 16:40:48.230 | 26/01/16 22:40:48 INFO BlockManagerMasterEndpoint: Registering block manager 10.1.4.101:41685 with 413.9 MiB RAM, BlockManagerId(1, 10.1.4.101, 41685, None)
2026-01-16 16:40:48.238 | 26/01/16 22:40:48 INFO BlockManagerMasterEndpoint: Registering block manager 10.1.4.102:38429 with 413.9 MiB RAM, BlockManagerId(2, 10.1.4.102, 38429, None)
2026-01-16 16:40:49.703 | 2026-01-16 22:40:49,702 - SparkPreprocessing - INFO - Starting preprocessing for train dataset
2026-01-16 16:40:49.703 | 2026-01-16 22:40:49,703 - SparkPreprocessing - INFO - Loading feature pipeline: preprocessing.preprocessing_001
2026-01-16 16:40:49.704 | 2026-01-16 22:40:49,704 - SparkPreprocessing - INFO - Loading data from s3a://k8s-mlops-platform-bucket/v1/raw/train/
2026-01-16 16:40:49.769 | 26/01/16 22:40:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2026-01-16 16:40:49.775 | 26/01/16 22:40:49 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.
2026-01-16 16:40:50.321 | 26/01/16 22:40:50 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2026-01-16 16:40:50.329 | 26/01/16 22:40:50 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2026-01-16 16:40:50.329 | 26/01/16 22:40:50 INFO MetricsSystemImpl: s3a-file-system metrics system started
2026-01-16 16:40:51.848 | 26/01/16 22:40:51 INFO HadoopFSUtils: Listing s3a://k8s-mlops-platform-bucket/v1/raw/train with listFiles API
2026-01-16 16:40:51.995 | 26/01/16 22:40:51 INFO InMemoryFileIndex: It took 150 ms to list leaf files for 1 paths.
2026-01-16 16:40:52.326 | 26/01/16 22:40:52 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:40:52.329 | 26/01/16 22:40:52 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:40:52.560 | 26/01/16 22:40:52 INFO CodeGenerator: Code generated in 129.520293 ms
2026-01-16 16:40:52.582 | 26/01/16 22:40:52 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
2026-01-16 16:40:52.609 | 26/01/16 22:40:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 237.9 KiB, free 413.7 MiB)
2026-01-16 16:40:52.645 | 26/01/16 22:40:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 41.4 KiB, free 413.7 MiB)
2026-01-16 16:40:52.650 | 26/01/16 22:40:52 INFO SparkContext: Created broadcast 0 from javaToPython at NativeMethodAccessorImpl.java:0
2026-01-16 16:40:52.664 | 26/01/16 22:40:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:40:52.750 | 2026-01-16 22:40:52,749 - SparkPreprocessing - INFO - Data loaded successfully | partitions: 1
2026-01-16 16:40:53.094 | 26/01/16 22:40:53 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:40:53.094 | 26/01/16 22:40:53 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:40:53.225 | 26/01/16 22:40:53 INFO CodeGenerator: Code generated in 47.972436 ms
2026-01-16 16:40:53.229 | 26/01/16 22:40:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 237.0 KiB, free 413.4 MiB)
2026-01-16 16:40:53.249 | 26/01/16 22:40:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 41.2 KiB, free 413.4 MiB)
2026-01-16 16:40:53.251 | 26/01/16 22:40:53 INFO SparkContext: Created broadcast 1 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2026-01-16 16:40:53.252 | 26/01/16 22:40:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:40:53.336 | 26/01/16 22:40:53 INFO DAGScheduler: Registering RDD 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2026-01-16 16:40:53.340 | 26/01/16 22:40:53 INFO DAGScheduler: Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2026-01-16 16:40:53.341 | 26/01/16 22:40:53 INFO DAGScheduler: Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2026-01-16 16:40:53.342 | 26/01/16 22:40:53 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:40:53.343 | 26/01/16 22:40:53 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:40:53.346 | 26/01/16 22:40:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2026-01-16 16:40:53.368 | 26/01/16 22:40:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 30.7 KiB, free 413.4 MiB)
2026-01-16 16:40:53.370 | 26/01/16 22:40:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 413.3 MiB)
2026-01-16 16:40:53.372 | 26/01/16 22:40:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:40:53.387 | 26/01/16 22:40:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:40:53.395 | 26/01/16 22:40:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2026-01-16 16:40:53.420 | 26/01/16 22:40:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.1.4.102,executor 2, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:40:56.453 | 26/01/16 22:40:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3043 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:40:56.454 | 26/01/16 22:40:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0 whose tasks have all completed, from pool 
2026-01-16 16:40:56.458 | 26/01/16 22:40:56 INFO DAGScheduler: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3103 ms
2026-01-16 16:40:56.458 | 26/01/16 22:40:56 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:40:56.460 | 26/01/16 22:40:56 INFO DAGScheduler: running: HashSet()
2026-01-16 16:40:56.460 | 26/01/16 22:40:56 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:40:56.460 | 26/01/16 22:40:56 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:40:56.471 | 26/01/16 22:40:56 INFO ShufflePartitionsUtil: For shuffle(0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2026-01-16 16:40:56.522 | 26/01/16 22:40:56 INFO CodeGenerator: Code generated in 38.98539 ms
2026-01-16 16:40:56.585 | 26/01/16 22:40:56 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54
2026-01-16 16:40:56.588 | 26/01/16 22:40:56 INFO DAGScheduler: Got job 1 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) with 1 output partitions
2026-01-16 16:40:56.589 | 26/01/16 22:40:56 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54)
2026-01-16 16:40:56.589 | 26/01/16 22:40:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
2026-01-16 16:40:56.590 | 26/01/16 22:40:56 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:40:56.591 | 26/01/16 22:40:56 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[15] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54), which has no missing parents
2026-01-16 16:40:56.600 | 26/01/16 22:40:56 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 44.9 KiB, free 413.3 MiB)
2026-01-16 16:40:56.601 | 26/01/16 22:40:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 413.3 MiB)
2026-01-16 16:40:56.602 | 26/01/16 22:40:56 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:40:56.604 | 26/01/16 22:40:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[15] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:40:56.604 | 26/01/16 22:40:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2026-01-16 16:40:56.609 | 26/01/16 22:40:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (10.1.4.102,executor 2, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:40:56.777 | 26/01/16 22:40:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.1.4.102:49030
2026-01-16 16:40:57.490 | 26/01/16 22:40:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 883 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:40:57.490 | 26/01/16 22:40:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0 whose tasks have all completed, from pool 
2026-01-16 16:40:57.492 | 26/01/16 22:40:57 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 40521
2026-01-16 16:40:57.493 | 26/01/16 22:40:57 INFO DAGScheduler: ResultStage 2 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) finished in 895 ms
2026-01-16 16:40:57.494 | 26/01/16 22:40:57 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:40:57.494 | 26/01/16 22:40:57 INFO TaskSchedulerImpl: Canceling stage 2
2026-01-16 16:40:57.495 | 26/01/16 22:40:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2026-01-16 16:40:57.496 | 26/01/16 22:40:57 INFO DAGScheduler: Job 1 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54, took 910.677668 ms
2026-01-16 16:40:57.520 | 26/01/16 22:40:57 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:40:57.520 | 26/01/16 22:40:57 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:40:57.532 | 26/01/16 22:40:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 237.0 KiB, free 413.1 MiB)
2026-01-16 16:40:57.543 | 26/01/16 22:40:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 413.0 MiB)
2026-01-16 16:40:57.544 | 26/01/16 22:40:57 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2026-01-16 16:40:57.545 | 26/01/16 22:40:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:40:57.551 | 26/01/16 22:40:57 INFO DAGScheduler: Registering RDD 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2026-01-16 16:40:57.551 | 26/01/16 22:40:57 INFO DAGScheduler: Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2026-01-16 16:40:57.552 | 26/01/16 22:40:57 INFO DAGScheduler: Final stage: ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2026-01-16 16:40:57.552 | 26/01/16 22:40:57 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:40:57.552 | 26/01/16 22:40:57 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:40:57.553 | 26/01/16 22:40:57 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2026-01-16 16:40:57.555 | 26/01/16 22:40:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 30.7 KiB, free 413.0 MiB)
2026-01-16 16:40:57.557 | 26/01/16 22:40:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 413.0 MiB)
2026-01-16 16:40:57.558 | 26/01/16 22:40:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:40:57.559 | 26/01/16 22:40:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:40:57.559 | 26/01/16 22:40:57 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
2026-01-16 16:40:57.561 | 26/01/16 22:40:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:00.613 | 26/01/16 22:41:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 3052 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:00.613 | 26/01/16 22:41:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0 whose tasks have all completed, from pool 
2026-01-16 16:41:00.613 | 26/01/16 22:41:00 INFO DAGScheduler: ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 3059 ms
2026-01-16 16:41:00.613 | 26/01/16 22:41:00 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:00.614 | 26/01/16 22:41:00 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:00.614 | 26/01/16 22:41:00 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:00.614 | 26/01/16 22:41:00 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:00.616 | 26/01/16 22:41:00 INFO ShufflePartitionsUtil: For shuffle(1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2026-01-16 16:41:00.636 | 26/01/16 22:41:00 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54
2026-01-16 16:41:00.637 | 26/01/16 22:41:00 INFO DAGScheduler: Got job 3 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) with 1 output partitions
2026-01-16 16:41:00.637 | 26/01/16 22:41:00 INFO DAGScheduler: Final stage: ResultStage 5 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54)
2026-01-16 16:41:00.637 | 26/01/16 22:41:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
2026-01-16 16:41:00.637 | 26/01/16 22:41:00 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:00.638 | 26/01/16 22:41:00 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[25] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54), which has no missing parents
2026-01-16 16:41:00.641 | 26/01/16 22:41:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 44.9 KiB, free 413.0 MiB)
2026-01-16 16:41:00.643 | 26/01/16 22:41:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 413.0 MiB)
2026-01-16 16:41:00.645 | 26/01/16 22:41:00 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:00.645 | 26/01/16 22:41:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[25] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:00.645 | 26/01/16 22:41:00 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
2026-01-16 16:41:00.647 | 26/01/16 22:41:00 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:00.792 | 26/01/16 22:41:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.1.4.101:39260
2026-01-16 16:41:01.386 | 26/01/16 22:41:01 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 739 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:01.386 | 26/01/16 22:41:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0 whose tasks have all completed, from pool 
2026-01-16 16:41:01.387 | 26/01/16 22:41:01 INFO DAGScheduler: ResultStage 5 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) finished in 748 ms
2026-01-16 16:41:01.387 | 26/01/16 22:41:01 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:01.388 | 26/01/16 22:41:01 INFO TaskSchedulerImpl: Canceling stage 5
2026-01-16 16:41:01.388 | 26/01/16 22:41:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
2026-01-16 16:41:01.389 | 26/01/16 22:41:01 INFO DAGScheduler: Job 3 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54, took 751.856975 ms
2026-01-16 16:41:01.413 | 26/01/16 22:41:01 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:01.413 | 26/01/16 22:41:01 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:01.466 | 26/01/16 22:41:01 INFO CodeGenerator: Code generated in 25.793107 ms
2026-01-16 16:41:01.469 | 26/01/16 22:41:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 237.1 KiB, free 412.8 MiB)
2026-01-16 16:41:01.478 | 26/01/16 22:41:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 41.2 KiB, free 412.7 MiB)
2026-01-16 16:41:01.480 | 26/01/16 22:41:01 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2026-01-16 16:41:01.481 | 26/01/16 22:41:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:01.491 | 26/01/16 22:41:01 INFO DAGScheduler: Registering RDD 29 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2026-01-16 16:41:01.491 | 26/01/16 22:41:01 INFO DAGScheduler: Got map stage job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2026-01-16 16:41:01.491 | 26/01/16 22:41:01 INFO DAGScheduler: Final stage: ShuffleMapStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2026-01-16 16:41:01.491 | 26/01/16 22:41:01 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:01.491 | 26/01/16 22:41:01 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:01.492 | 26/01/16 22:41:01 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2026-01-16 16:41:01.494 | 26/01/16 22:41:01 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 32.4 KiB, free 412.7 MiB)
2026-01-16 16:41:01.495 | 26/01/16 22:41:01 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 412.7 MiB)
2026-01-16 16:41:01.497 | 26/01/16 22:41:01 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:01.497 | 26/01/16 22:41:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:01.498 | 26/01/16 22:41:01 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
2026-01-16 16:41:01.500 | 26/01/16 22:41:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:02.638 | 26/01/16 22:41:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 1139 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0 whose tasks have all completed, from pool 
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO DAGScheduler: ShuffleMapStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1147 ms
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:02.639 | 26/01/16 22:41:02 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:02.641 | 26/01/16 22:41:02 INFO ShufflePartitionsUtil: For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2026-01-16 16:41:02.671 | 26/01/16 22:41:02 INFO CodeGenerator: Code generated in 25.418549 ms
2026-01-16 16:41:02.702 | 26/01/16 22:41:02 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54
2026-01-16 16:41:02.704 | 26/01/16 22:41:02 INFO DAGScheduler: Got job 5 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) with 1 output partitions
2026-01-16 16:41:02.704 | 26/01/16 22:41:02 INFO DAGScheduler: Final stage: ResultStage 8 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54)
2026-01-16 16:41:02.704 | 26/01/16 22:41:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
2026-01-16 16:41:02.704 | 26/01/16 22:41:02 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:02.705 | 26/01/16 22:41:02 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[35] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54), which has no missing parents
2026-01-16 16:41:02.709 | 26/01/16 22:41:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 46.0 KiB, free 412.8 MiB)
2026-01-16 16:41:02.711 | 26/01/16 22:41:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 412.8 MiB)
2026-01-16 16:41:02.712 | 26/01/16 22:41:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:02.712 | 26/01/16 22:41:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (PythonRDD[35] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:02.712 | 26/01/16 22:41:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
2026-01-16 16:41:02.714 | 26/01/16 22:41:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:02.737 | 26/01/16 22:41:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.1.4.101:39260
2026-01-16 16:41:02.857 | 26/01/16 22:41:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 144 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:02.857 | 26/01/16 22:41:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0 whose tasks have all completed, from pool 
2026-01-16 16:41:02.858 | 26/01/16 22:41:02 INFO DAGScheduler: ResultStage 8 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54) finished in 151 ms
2026-01-16 16:41:02.858 | 26/01/16 22:41:02 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:02.859 | 26/01/16 22:41:02 INFO TaskSchedulerImpl: Canceling stage 8
2026-01-16 16:41:02.859 | 26/01/16 22:41:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
2026-01-16 16:41:02.859 | 26/01/16 22:41:02 INFO DAGScheduler: Job 5 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:54, took 156.379527 ms
2026-01-16 16:41:02.938 | 26/01/16 22:41:02 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:02.938 | 26/01/16 22:41:02 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:03.015 | 26/01/16 22:41:03 INFO CodeGenerator: Code generated in 20.705358 ms
2026-01-16 16:41:03.019 | 26/01/16 22:41:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 237.0 KiB, free 412.5 MiB)
2026-01-16 16:41:03.028 | 26/01/16 22:41:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 412.5 MiB)
2026-01-16 16:41:03.030 | 26/01/16 22:41:03 INFO SparkContext: Created broadcast 10 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:03.031 | 26/01/16 22:41:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:03.045 | 26/01/16 22:41:03 INFO DAGScheduler: Registering RDD 39 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 3
2026-01-16 16:41:03.045 | 26/01/16 22:41:03 INFO DAGScheduler: Got map stage job 6 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:03.045 | 26/01/16 22:41:03 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:03.045 | 26/01/16 22:41:03 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:03.046 | 26/01/16 22:41:03 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:03.046 | 26/01/16 22:41:03 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:03.049 | 26/01/16 22:41:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 26.4 KiB, free 412.5 MiB)
2026-01-16 16:41:03.051 | 26/01/16 22:41:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 412.5 MiB)
2026-01-16 16:41:03.052 | 26/01/16 22:41:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:03.052 | 26/01/16 22:41:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:03.053 | 26/01/16 22:41:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
2026-01-16 16:41:03.056 | 26/01/16 22:41:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (10.1.4.102,executor 2, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 1055 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Removed TaskSet 9.0 whose tasks have all completed, from pool 
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO DAGScheduler: ShuffleMapStage 9 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 1065 ms
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:04.111 | 26/01/16 22:41:04 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:04.159 | 26/01/16 22:41:04 INFO CodeGenerator: Code generated in 19.873797 ms
2026-01-16 16:41:04.174 | 26/01/16 22:41:04 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:04.175 | 26/01/16 22:41:04 INFO DAGScheduler: Got job 7 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:04.175 | 26/01/16 22:41:04 INFO DAGScheduler: Final stage: ResultStage 11 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:04.175 | 26/01/16 22:41:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
2026-01-16 16:41:04.176 | 26/01/16 22:41:04 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:04.176 | 26/01/16 22:41:04 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[42] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:04.178 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 21.4 KiB, free 412.5 MiB)
2026-01-16 16:41:04.180 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 412.5 MiB)
2026-01-16 16:41:04.181 | 26/01/16 22:41:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:04.182 | 26/01/16 22:41:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[42] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:04.182 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
2026-01-16 16:41:04.184 | 26/01/16 22:41:04 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (10.1.4.102,executor 2, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:04.210 | 26/01/16 22:41:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.1.4.102:49030
2026-01-16 16:41:04.254 | 26/01/16 22:41:04 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 70 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:04.254 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Removed TaskSet 11.0 whose tasks have all completed, from pool 
2026-01-16 16:41:04.255 | 26/01/16 22:41:04 INFO DAGScheduler: ResultStage 11 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 77 ms
2026-01-16 16:41:04.255 | 26/01/16 22:41:04 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:04.255 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Canceling stage 11
2026-01-16 16:41:04.255 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
2026-01-16 16:41:04.256 | 26/01/16 22:41:04 INFO DAGScheduler: Job 7 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 81.666518 ms
2026-01-16 16:41:04.315 | 26/01/16 22:41:04 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:04.315 | 26/01/16 22:41:04 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:04.347 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 237.0 KiB, free 412.3 MiB)
2026-01-16 16:41:04.358 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 412.2 MiB)
2026-01-16 16:41:04.361 | 26/01/16 22:41:04 INFO SparkContext: Created broadcast 13 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:04.362 | 26/01/16 22:41:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:04.365 | 26/01/16 22:41:04 INFO DAGScheduler: Registering RDD 46 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 4
2026-01-16 16:41:04.365 | 26/01/16 22:41:04 INFO DAGScheduler: Got map stage job 8 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:04.365 | 26/01/16 22:41:04 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:04.366 | 26/01/16 22:41:04 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:04.366 | 26/01/16 22:41:04 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:04.366 | 26/01/16 22:41:04 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[46] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:04.369 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 26.4 KiB, free 412.2 MiB)
2026-01-16 16:41:04.378 | 26/01/16 22:41:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 412.2 MiB)
2026-01-16 16:41:04.379 | 26/01/16 22:41:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:04.380 | 26/01/16 22:41:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[46] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:04.380 | 26/01/16 22:41:04 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
2026-01-16 16:41:04.382 | 26/01/16 22:41:04 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:05.374 | 26/01/16 22:41:05 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 993 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:05.374 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Removed TaskSet 12.0 whose tasks have all completed, from pool 
2026-01-16 16:41:05.375 | 26/01/16 22:41:05 INFO DAGScheduler: ShuffleMapStage 12 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 1007 ms
2026-01-16 16:41:05.375 | 26/01/16 22:41:05 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:05.375 | 26/01/16 22:41:05 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:05.375 | 26/01/16 22:41:05 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:05.375 | 26/01/16 22:41:05 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:05.390 | 26/01/16 22:41:05 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:05.391 | 26/01/16 22:41:05 INFO DAGScheduler: Got job 9 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:05.391 | 26/01/16 22:41:05 INFO DAGScheduler: Final stage: ResultStage 14 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:05.391 | 26/01/16 22:41:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
2026-01-16 16:41:05.391 | 26/01/16 22:41:05 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:05.391 | 26/01/16 22:41:05 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[49] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:05.392 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 21.4 KiB, free 412.2 MiB)
2026-01-16 16:41:05.393 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 412.2 MiB)
2026-01-16 16:41:05.394 | 26/01/16 22:41:05 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:05.394 | 26/01/16 22:41:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[49] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:05.394 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
2026-01-16 16:41:05.395 | 26/01/16 22:41:05 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:05.411 | 26/01/16 22:41:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.1.4.101:39260
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 46 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Removed TaskSet 14.0 whose tasks have all completed, from pool 
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO DAGScheduler: ResultStage 14 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 50 ms
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Canceling stage 14
2026-01-16 16:41:05.441 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
2026-01-16 16:41:05.442 | 26/01/16 22:41:05 INFO DAGScheduler: Job 9 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 51.616278 ms
2026-01-16 16:41:05.477 | 26/01/16 22:41:05 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:05.477 | 26/01/16 22:41:05 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:05.497 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 237.0 KiB, free 412.0 MiB)
2026-01-16 16:41:05.504 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 412.0 MiB)
2026-01-16 16:41:05.505 | 26/01/16 22:41:05 INFO SparkContext: Created broadcast 16 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:05.506 | 26/01/16 22:41:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:05.509 | 26/01/16 22:41:05 INFO DAGScheduler: Registering RDD 53 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 5
2026-01-16 16:41:05.509 | 26/01/16 22:41:05 INFO DAGScheduler: Got map stage job 10 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:05.509 | 26/01/16 22:41:05 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:05.509 | 26/01/16 22:41:05 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:05.510 | 26/01/16 22:41:05 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:05.510 | 26/01/16 22:41:05 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[53] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:05.512 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 26.4 KiB, free 411.9 MiB)
2026-01-16 16:41:05.513 | 26/01/16 22:41:05 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 411.9 MiB)
2026-01-16 16:41:05.514 | 26/01/16 22:41:05 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:05.514 | 26/01/16 22:41:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[53] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:05.514 | 26/01/16 22:41:05 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
2026-01-16 16:41:05.515 | 26/01/16 22:41:05 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 10) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:06.450 | 26/01/16 22:41:06 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 10) in 934 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:06.450 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Removed TaskSet 15.0 whose tasks have all completed, from pool 
2026-01-16 16:41:06.450 | 26/01/16 22:41:06 INFO DAGScheduler: ShuffleMapStage 15 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 940 ms
2026-01-16 16:41:06.450 | 26/01/16 22:41:06 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:06.450 | 26/01/16 22:41:06 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:06.451 | 26/01/16 22:41:06 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:06.451 | 26/01/16 22:41:06 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:06.473 | 26/01/16 22:41:06 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:06.475 | 26/01/16 22:41:06 INFO DAGScheduler: Got job 11 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:06.475 | 26/01/16 22:41:06 INFO DAGScheduler: Final stage: ResultStage 17 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:06.475 | 26/01/16 22:41:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
2026-01-16 16:41:06.475 | 26/01/16 22:41:06 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:06.476 | 26/01/16 22:41:06 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[56] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:06.479 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 21.4 KiB, free 411.9 MiB)
2026-01-16 16:41:06.481 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 411.9 MiB)
2026-01-16 16:41:06.482 | 26/01/16 22:41:06 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:06.482 | 26/01/16 22:41:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[56] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:06.483 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
2026-01-16 16:41:06.485 | 26/01/16 22:41:06 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 11) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:06.511 | 26/01/16 22:41:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.1.4.101:39260
2026-01-16 16:41:06.523 | 26/01/16 22:41:06 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 11) in 39 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:06.523 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Removed TaskSet 17.0 whose tasks have all completed, from pool 
2026-01-16 16:41:06.524 | 26/01/16 22:41:06 INFO DAGScheduler: ResultStage 17 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 47 ms
2026-01-16 16:41:06.525 | 26/01/16 22:41:06 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:06.525 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Canceling stage 17
2026-01-16 16:41:06.525 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
2026-01-16 16:41:06.525 | 26/01/16 22:41:06 INFO DAGScheduler: Job 11 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 51.663545 ms
2026-01-16 16:41:06.564 | 26/01/16 22:41:06 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:06.564 | 26/01/16 22:41:06 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:06.595 | 26/01/16 22:41:06 INFO CodeGenerator: Code generated in 13.64085 ms
2026-01-16 16:41:06.598 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 237.0 KiB, free 411.8 MiB)
2026-01-16 16:41:06.605 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 411.7 MiB)
2026-01-16 16:41:06.607 | 26/01/16 22:41:06 INFO SparkContext: Created broadcast 19 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:06.608 | 26/01/16 22:41:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:06.611 | 26/01/16 22:41:06 INFO DAGScheduler: Registering RDD 60 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 6
2026-01-16 16:41:06.611 | 26/01/16 22:41:06 INFO DAGScheduler: Got map stage job 12 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:06.611 | 26/01/16 22:41:06 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:06.611 | 26/01/16 22:41:06 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:06.611 | 26/01/16 22:41:06 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:06.612 | 26/01/16 22:41:06 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[60] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:06.613 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 26.2 KiB, free 411.7 MiB)
2026-01-16 16:41:06.615 | 26/01/16 22:41:06 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 411.7 MiB)
2026-01-16 16:41:06.616 | 26/01/16 22:41:06 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:06.616 | 26/01/16 22:41:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[60] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:06.616 | 26/01/16 22:41:06 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
2026-01-16 16:41:06.618 | 26/01/16 22:41:06 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 12) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:07.620 | 26/01/16 22:41:07 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 12) in 1002 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:07.620 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Removed TaskSet 18.0 whose tasks have all completed, from pool 
2026-01-16 16:41:07.622 | 26/01/16 22:41:07 INFO DAGScheduler: ShuffleMapStage 18 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 1009 ms
2026-01-16 16:41:07.624 | 26/01/16 22:41:07 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:07.624 | 26/01/16 22:41:07 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:07.624 | 26/01/16 22:41:07 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:07.624 | 26/01/16 22:41:07 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:07.638 | 26/01/16 22:41:07 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO DAGScheduler: Got job 13 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO DAGScheduler: Final stage: ResultStage 20 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[63] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:07.639 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 21.4 KiB, free 411.7 MiB)
2026-01-16 16:41:07.645 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 411.7 MiB)
2026-01-16 16:41:07.647 | 26/01/16 22:41:07 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:07.647 | 26/01/16 22:41:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[63] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:07.648 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
2026-01-16 16:41:07.650 | 26/01/16 22:41:07 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 13) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:07.671 | 26/01/16 22:41:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.1.4.101:39260
2026-01-16 16:41:07.681 | 26/01/16 22:41:07 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 13) in 32 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Removed TaskSet 20.0 whose tasks have all completed, from pool 
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO DAGScheduler: ResultStage 20 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 43 ms
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Canceling stage 20
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
2026-01-16 16:41:07.682 | 26/01/16 22:41:07 INFO DAGScheduler: Job 13 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 44.671767 ms
2026-01-16 16:41:07.732 | 26/01/16 22:41:07 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:07.733 | 26/01/16 22:41:07 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:07.772 | 26/01/16 22:41:07 INFO CodeGenerator: Code generated in 14.938115 ms
2026-01-16 16:41:07.775 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 237.0 KiB, free 411.8 MiB)
2026-01-16 16:41:07.783 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 411.7 MiB)
2026-01-16 16:41:07.784 | 26/01/16 22:41:07 INFO SparkContext: Created broadcast 22 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:07.785 | 26/01/16 22:41:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:07.788 | 26/01/16 22:41:07 INFO DAGScheduler: Registering RDD 67 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 7
2026-01-16 16:41:07.788 | 26/01/16 22:41:07 INFO DAGScheduler: Got map stage job 14 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:07.788 | 26/01/16 22:41:07 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:07.788 | 26/01/16 22:41:07 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:07.788 | 26/01/16 22:41:07 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:07.789 | 26/01/16 22:41:07 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[67] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:07.791 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 26.6 KiB, free 411.7 MiB)
2026-01-16 16:41:07.792 | 26/01/16 22:41:07 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 411.7 MiB)
2026-01-16 16:41:07.794 | 26/01/16 22:41:07 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:07.794 | 26/01/16 22:41:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[67] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:07.794 | 26/01/16 22:41:07 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
2026-01-16 16:41:07.796 | 26/01/16 22:41:07 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 14) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 14) in 976 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Removed TaskSet 21.0 whose tasks have all completed, from pool 
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO DAGScheduler: ShuffleMapStage 21 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 982 ms
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:08.771 | 26/01/16 22:41:08 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:08.783 | 26/01/16 22:41:08 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:08.783 | 26/01/16 22:41:08 INFO DAGScheduler: Got job 15 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:08.783 | 26/01/16 22:41:08 INFO DAGScheduler: Final stage: ResultStage 23 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:08.783 | 26/01/16 22:41:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
2026-01-16 16:41:08.783 | 26/01/16 22:41:08 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:08.784 | 26/01/16 22:41:08 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[70] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:08.785 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 21.4 KiB, free 411.7 MiB)
2026-01-16 16:41:08.786 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 411.7 MiB)
2026-01-16 16:41:08.786 | 26/01/16 22:41:08 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:08.787 | 26/01/16 22:41:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[70] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:08.787 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
2026-01-16 16:41:08.788 | 26/01/16 22:41:08 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 15) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:08.802 | 26/01/16 22:41:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.1.4.101:39260
2026-01-16 16:41:08.815 | 26/01/16 22:41:08 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 15) in 28 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Removed TaskSet 23.0 whose tasks have all completed, from pool 
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO DAGScheduler: ResultStage 23 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 31 ms
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Canceling stage 23
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
2026-01-16 16:41:08.817 | 26/01/16 22:41:08 INFO DAGScheduler: Job 15 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 33.005341 ms
2026-01-16 16:41:08.858 | 26/01/16 22:41:08 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:08.858 | 26/01/16 22:41:08 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:08.890 | 26/01/16 22:41:08 INFO CodeGenerator: Code generated in 13.78022 ms
2026-01-16 16:41:08.892 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 237.0 KiB, free 411.5 MiB)
2026-01-16 16:41:08.899 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 411.4 MiB)
2026-01-16 16:41:08.899 | 26/01/16 22:41:08 INFO SparkContext: Created broadcast 25 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:08.900 | 26/01/16 22:41:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:08.903 | 26/01/16 22:41:08 INFO DAGScheduler: Registering RDD 74 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 8
2026-01-16 16:41:08.903 | 26/01/16 22:41:08 INFO DAGScheduler: Got map stage job 16 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:08.904 | 26/01/16 22:41:08 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:08.904 | 26/01/16 22:41:08 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:08.904 | 26/01/16 22:41:08 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:08.904 | 26/01/16 22:41:08 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[74] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:08.905 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 26.7 KiB, free 411.4 MiB)
2026-01-16 16:41:08.906 | 26/01/16 22:41:08 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 411.4 MiB)
2026-01-16 16:41:08.907 | 26/01/16 22:41:08 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:08.907 | 26/01/16 22:41:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[74] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:08.907 | 26/01/16 22:41:08 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
2026-01-16 16:41:08.908 | 26/01/16 22:41:08 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 16) (10.1.4.102,executor 2, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 16) in 958 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO TaskSchedulerImpl: Removed TaskSet 24.0 whose tasks have all completed, from pool 
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO DAGScheduler: ShuffleMapStage 24 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 963 ms
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:09.867 | 26/01/16 22:41:09 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:09.883 | 26/01/16 22:41:09 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:09.884 | 26/01/16 22:41:09 INFO DAGScheduler: Got job 17 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:09.884 | 26/01/16 22:41:09 INFO DAGScheduler: Final stage: ResultStage 26 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:09.884 | 26/01/16 22:41:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
2026-01-16 16:41:09.884 | 26/01/16 22:41:09 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:09.884 | 26/01/16 22:41:09 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[77] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:09.885 | 26/01/16 22:41:09 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 21.4 KiB, free 411.4 MiB)
2026-01-16 16:41:09.887 | 26/01/16 22:41:09 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 411.4 MiB)
2026-01-16 16:41:09.887 | 26/01/16 22:41:09 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:09.888 | 26/01/16 22:41:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[77] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:09.888 | 26/01/16 22:41:09 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
2026-01-16 16:41:09.889 | 26/01/16 22:41:09 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 17) (10.1.4.102,executor 2, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:09.909 | 26/01/16 22:41:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.1.4.102:49030
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 17) in 30 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO TaskSchedulerImpl: Removed TaskSet 26.0 whose tasks have all completed, from pool 
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO DAGScheduler: ResultStage 26 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 35 ms
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO TaskSchedulerImpl: Canceling stage 26
2026-01-16 16:41:09.919 | 26/01/16 22:41:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
2026-01-16 16:41:09.920 | 26/01/16 22:41:09 INFO DAGScheduler: Job 17 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 36.471567 ms
2026-01-16 16:41:09.945 | 26/01/16 22:41:09 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:09.945 | 26/01/16 22:41:09 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:09.984 | 26/01/16 22:41:09 INFO CodeGenerator: Code generated in 24.726715 ms
2026-01-16 16:41:09.988 | 26/01/16 22:41:09 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 237.0 KiB, free 411.2 MiB)
2026-01-16 16:41:09.995 | 26/01/16 22:41:09 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 411.2 MiB)
2026-01-16 16:41:09.996 | 26/01/16 22:41:09 INFO SparkContext: Created broadcast 28 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:09.997 | 26/01/16 22:41:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Registering RDD 81 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 9
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Got map stage job 18 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:10.001 | 26/01/16 22:41:10 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[81] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:10.003 | 26/01/16 22:41:10 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.0 KiB, free 411.2 MiB)
2026-01-16 16:41:10.004 | 26/01/16 22:41:10 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 411.2 MiB)
2026-01-16 16:41:10.004 | 26/01/16 22:41:10 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:10.004 | 26/01/16 22:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[81] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:10.005 | 26/01/16 22:41:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
2026-01-16 16:41:10.006 | 26/01/16 22:41:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 18) (10.1.4.102,executor 2, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:10.980 | 26/01/16 22:41:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 18) in 975 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:10.980 | 26/01/16 22:41:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0 whose tasks have all completed, from pool 
2026-01-16 16:41:10.981 | 26/01/16 22:41:10 INFO DAGScheduler: ShuffleMapStage 27 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 979 ms
2026-01-16 16:41:10.981 | 26/01/16 22:41:10 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:10.981 | 26/01/16 22:41:10 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:10.981 | 26/01/16 22:41:10 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:10.981 | 26/01/16 22:41:10 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO DAGScheduler: Got job 19 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO DAGScheduler: Final stage: ResultStage 29 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:10.995 | 26/01/16 22:41:10 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[84] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:10.997 | 26/01/16 22:41:10 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 21.4 KiB, free 411.1 MiB)
2026-01-16 16:41:10.997 | 26/01/16 22:41:10 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 411.1 MiB)
2026-01-16 16:41:10.998 | 26/01/16 22:41:10 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:10.999 | 26/01/16 22:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[84] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:10.999 | 26/01/16 22:41:10 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
2026-01-16 16:41:11.000 | 26/01/16 22:41:11 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 19) (10.1.4.102,executor 2, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:11.022 | 26/01/16 22:41:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.1.4.102:49030
2026-01-16 16:41:11.037 | 26/01/16 22:41:11 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 19) in 36 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:11.037 | 26/01/16 22:41:11 INFO TaskSchedulerImpl: Removed TaskSet 29.0 whose tasks have all completed, from pool 
2026-01-16 16:41:11.037 | 26/01/16 22:41:11 INFO DAGScheduler: ResultStage 29 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 42 ms
2026-01-16 16:41:11.038 | 26/01/16 22:41:11 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:11.038 | 26/01/16 22:41:11 INFO TaskSchedulerImpl: Canceling stage 29
2026-01-16 16:41:11.038 | 26/01/16 22:41:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
2026-01-16 16:41:11.038 | 26/01/16 22:41:11 INFO DAGScheduler: Job 19 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 43.450745 ms
2026-01-16 16:41:11.077 | 26/01/16 22:41:11 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:11.077 | 26/01/16 22:41:11 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:11.108 | 26/01/16 22:41:11 INFO CodeGenerator: Code generated in 13.080164 ms
2026-01-16 16:41:11.110 | 26/01/16 22:41:11 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 237.0 KiB, free 410.9 MiB)
2026-01-16 16:41:11.126 | 26/01/16 22:41:11 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 410.9 MiB)
2026-01-16 16:41:11.127 | 26/01/16 22:41:11 INFO SparkContext: Created broadcast 31 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:11.128 | 26/01/16 22:41:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:11.131 | 26/01/16 22:41:11 INFO DAGScheduler: Registering RDD 88 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 10
2026-01-16 16:41:11.131 | 26/01/16 22:41:11 INFO DAGScheduler: Got map stage job 20 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:11.131 | 26/01/16 22:41:11 INFO DAGScheduler: Final stage: ShuffleMapStage 30 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:11.131 | 26/01/16 22:41:11 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:11.132 | 26/01/16 22:41:11 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:11.132 | 26/01/16 22:41:11 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[88] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:11.133 | 26/01/16 22:41:11 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 28.3 KiB, free 410.9 MiB)
2026-01-16 16:41:11.134 | 26/01/16 22:41:11 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 410.9 MiB)
2026-01-16 16:41:11.135 | 26/01/16 22:41:11 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:11.135 | 26/01/16 22:41:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[88] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:11.135 | 26/01/16 22:41:11 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
2026-01-16 16:41:11.137 | 26/01/16 22:41:11 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 20) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 20) in 949 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Removed TaskSet 30.0 whose tasks have all completed, from pool 
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO DAGScheduler: ShuffleMapStage 30 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 954 ms
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:12.086 | 26/01/16 22:41:12 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:12.098 | 26/01/16 22:41:12 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:12.098 | 26/01/16 22:41:12 INFO DAGScheduler: Got job 21 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:12.098 | 26/01/16 22:41:12 INFO DAGScheduler: Final stage: ResultStage 32 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:12.098 | 26/01/16 22:41:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
2026-01-16 16:41:12.098 | 26/01/16 22:41:12 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:12.099 | 26/01/16 22:41:12 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[91] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:12.099 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 21.4 KiB, free 410.9 MiB)
2026-01-16 16:41:12.101 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 410.9 MiB)
2026-01-16 16:41:12.101 | 26/01/16 22:41:12 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:12.101 | 26/01/16 22:41:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[91] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:12.102 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
2026-01-16 16:41:12.103 | 26/01/16 22:41:12 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 21) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:12.115 | 26/01/16 22:41:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.1.4.101:39260
2026-01-16 16:41:12.123 | 26/01/16 22:41:12 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 21) in 21 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:12.123 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Removed TaskSet 32.0 whose tasks have all completed, from pool 
2026-01-16 16:41:12.124 | 26/01/16 22:41:12 INFO DAGScheduler: ResultStage 32 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 24 ms
2026-01-16 16:41:12.124 | 26/01/16 22:41:12 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:12.124 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Canceling stage 32
2026-01-16 16:41:12.124 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
2026-01-16 16:41:12.124 | 26/01/16 22:41:12 INFO DAGScheduler: Job 21 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 26.168412 ms
2026-01-16 16:41:12.166 | 26/01/16 22:41:12 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:12.166 | 26/01/16 22:41:12 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:12.203 | 26/01/16 22:41:12 INFO CodeGenerator: Code generated in 14.406808 ms
2026-01-16 16:41:12.205 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 237.0 KiB, free 410.6 MiB)
2026-01-16 16:41:12.228 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 410.6 MiB)
2026-01-16 16:41:12.229 | 26/01/16 22:41:12 INFO SparkContext: Created broadcast 34 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:12.231 | 26/01/16 22:41:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:12.234 | 26/01/16 22:41:12 INFO DAGScheduler: Registering RDD 95 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 11
2026-01-16 16:41:12.234 | 26/01/16 22:41:12 INFO DAGScheduler: Got map stage job 22 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:12.234 | 26/01/16 22:41:12 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:12.234 | 26/01/16 22:41:12 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:12.234 | 26/01/16 22:41:12 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:12.235 | 26/01/16 22:41:12 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[95] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:12.238 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 28.3 KiB, free 410.6 MiB)
2026-01-16 16:41:12.239 | 26/01/16 22:41:12 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 410.6 MiB)
2026-01-16 16:41:12.241 | 26/01/16 22:41:12 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:12.241 | 26/01/16 22:41:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[95] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:12.241 | 26/01/16 22:41:12 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
2026-01-16 16:41:12.243 | 26/01/16 22:41:12 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 22) (10.1.4.102,executor 2, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 22) in 979 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Removed TaskSet 33.0 whose tasks have all completed, from pool 
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO DAGScheduler: ShuffleMapStage 33 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 986 ms
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:13.222 | 26/01/16 22:41:13 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:13.233 | 26/01/16 22:41:13 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:13.234 | 26/01/16 22:41:13 INFO DAGScheduler: Got job 23 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:13.234 | 26/01/16 22:41:13 INFO DAGScheduler: Final stage: ResultStage 35 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:13.234 | 26/01/16 22:41:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
2026-01-16 16:41:13.234 | 26/01/16 22:41:13 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:13.235 | 26/01/16 22:41:13 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[98] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:13.236 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.4 KiB, free 410.6 MiB)
2026-01-16 16:41:13.237 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 410.6 MiB)
2026-01-16 16:41:13.237 | 26/01/16 22:41:13 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:13.237 | 26/01/16 22:41:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[98] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:13.237 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
2026-01-16 16:41:13.238 | 26/01/16 22:41:13 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 23) (10.1.4.102,executor 2, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:13.250 | 26/01/16 22:41:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.1.4.102:49030
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 23) in 18 ms on 10.1.4.102 (executor 2) (1/1)
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Removed TaskSet 35.0 whose tasks have all completed, from pool 
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO DAGScheduler: ResultStage 35 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 21 ms
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Canceling stage 35
2026-01-16 16:41:13.256 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
2026-01-16 16:41:13.257 | 26/01/16 22:41:13 INFO DAGScheduler: Job 23 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 23.279462 ms
2026-01-16 16:41:13.285 | 26/01/16 22:41:13 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:13.285 | 26/01/16 22:41:13 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:13.319 | 26/01/16 22:41:13 INFO CodeGenerator: Code generated in 16.666095 ms
2026-01-16 16:41:13.322 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 237.0 KiB, free 410.4 MiB)
2026-01-16 16:41:13.330 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 410.3 MiB)
2026-01-16 16:41:13.331 | 26/01/16 22:41:13 INFO SparkContext: Created broadcast 37 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:13.332 | 26/01/16 22:41:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:13.334 | 26/01/16 22:41:13 INFO DAGScheduler: Registering RDD 102 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 12
2026-01-16 16:41:13.335 | 26/01/16 22:41:13 INFO DAGScheduler: Got map stage job 24 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:13.335 | 26/01/16 22:41:13 INFO DAGScheduler: Final stage: ShuffleMapStage 36 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:13.335 | 26/01/16 22:41:13 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:13.335 | 26/01/16 22:41:13 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:13.335 | 26/01/16 22:41:13 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[102] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:13.338 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 28.5 KiB, free 410.3 MiB)
2026-01-16 16:41:13.349 | 26/01/16 22:41:13 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 410.3 MiB)
2026-01-16 16:41:13.350 | 26/01/16 22:41:13 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:13.352 | 26/01/16 22:41:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[102] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:13.352 | 26/01/16 22:41:13 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
2026-01-16 16:41:13.354 | 26/01/16 22:41:13 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 24) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 24) in 931 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Removed TaskSet 36.0 whose tasks have all completed, from pool 
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO DAGScheduler: ShuffleMapStage 36 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 950 ms
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:14.285 | 26/01/16 22:41:14 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:14.296 | 26/01/16 22:41:14 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:14.297 | 26/01/16 22:41:14 INFO DAGScheduler: Got job 25 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:14.297 | 26/01/16 22:41:14 INFO DAGScheduler: Final stage: ResultStage 38 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:14.297 | 26/01/16 22:41:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
2026-01-16 16:41:14.297 | 26/01/16 22:41:14 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:14.297 | 26/01/16 22:41:14 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[105] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:14.298 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 21.4 KiB, free 410.3 MiB)
2026-01-16 16:41:14.298 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 410.3 MiB)
2026-01-16 16:41:14.299 | 26/01/16 22:41:14 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:14.299 | 26/01/16 22:41:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[105] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:14.299 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
2026-01-16 16:41:14.300 | 26/01/16 22:41:14 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 25) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:14.312 | 26/01/16 22:41:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.1.4.101:39260
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 25) in 18 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Removed TaskSet 38.0 whose tasks have all completed, from pool 
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO DAGScheduler: ResultStage 38 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 21 ms
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Canceling stage 38
2026-01-16 16:41:14.318 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
2026-01-16 16:41:14.319 | 26/01/16 22:41:14 INFO DAGScheduler: Job 25 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 22.983395 ms
2026-01-16 16:41:14.349 | 26/01/16 22:41:14 INFO FileSourceStrategy: Pushed Filters: 
2026-01-16 16:41:14.349 | 26/01/16 22:41:14 INFO FileSourceStrategy: Post-Scan Filters: Set()
2026-01-16 16:41:14.371 | 26/01/16 22:41:14 INFO CodeGenerator: Code generated in 10.597721 ms
2026-01-16 16:41:14.374 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 237.0 KiB, free 410.1 MiB)
2026-01-16 16:41:14.380 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 41.3 KiB, free 410.1 MiB)
2026-01-16 16:41:14.381 | 26/01/16 22:41:14 INFO SparkContext: Created broadcast 40 from collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:14.382 | 26/01/16 22:41:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2026-01-16 16:41:14.386 | 26/01/16 22:41:14 INFO DAGScheduler: Registering RDD 109 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) as input to shuffle 13
2026-01-16 16:41:14.387 | 26/01/16 22:41:14 INFO DAGScheduler: Got map stage job 26 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:14.387 | 26/01/16 22:41:14 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:14.387 | 26/01/16 22:41:14 INFO DAGScheduler: Parents of final stage: List()
2026-01-16 16:41:14.387 | 26/01/16 22:41:14 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:14.387 | 26/01/16 22:41:14 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[109] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:14.388 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 28.5 KiB, free 410.0 MiB)
2026-01-16 16:41:14.389 | 26/01/16 22:41:14 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 410.0 MiB)
2026-01-16 16:41:14.390 | 26/01/16 22:41:14 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:14.390 | 26/01/16 22:41:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[109] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:14.390 | 26/01/16 22:41:14 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
2026-01-16 16:41:14.391 | 26/01/16 22:41:14 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 26) (10.1.4.101,executor 1, partition 0, PROCESS_LOCAL, 10233 bytes) 
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 26) in 928 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO TaskSchedulerImpl: Removed TaskSet 39.0 whose tasks have all completed, from pool 
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO DAGScheduler: ShuffleMapStage 39 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 931 ms
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO DAGScheduler: looking for newly runnable stages
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO DAGScheduler: running: HashSet()
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO DAGScheduler: waiting: HashSet()
2026-01-16 16:41:15.318 | 26/01/16 22:41:15 INFO DAGScheduler: failed: HashSet()
2026-01-16 16:41:15.336 | 26/01/16 22:41:15 INFO SparkContext: Starting job: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87
2026-01-16 16:41:15.336 | 26/01/16 22:41:15 INFO DAGScheduler: Got job 27 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) with 1 output partitions
2026-01-16 16:41:15.336 | 26/01/16 22:41:15 INFO DAGScheduler: Final stage: ResultStage 41 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87)
2026-01-16 16:41:15.336 | 26/01/16 22:41:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
2026-01-16 16:41:15.336 | 26/01/16 22:41:15 INFO DAGScheduler: Missing parents: List()
2026-01-16 16:41:15.337 | 26/01/16 22:41:15 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[112] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87), which has no missing parents
2026-01-16 16:41:15.338 | 26/01/16 22:41:15 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 21.4 KiB, free 410.0 MiB)
2026-01-16 16:41:15.338 | 26/01/16 22:41:15 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 410.1 MiB)
2026-01-16 16:41:15.339 | 26/01/16 22:41:15 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1676
2026-01-16 16:41:15.339 | 26/01/16 22:41:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[112] at collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) (first 15 tasks are for partitions Vector(0))
2026-01-16 16:41:15.339 | 26/01/16 22:41:15 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
2026-01-16 16:41:15.341 | 26/01/16 22:41:15 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 27) (10.1.4.101,executor 1, partition 0, NODE_LOCAL, 9623 bytes) 
2026-01-16 16:41:15.358 | 26/01/16 22:41:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.1.4.101:39260
2026-01-16 16:41:15.364 | 26/01/16 22:41:15 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 27) in 24 ms on 10.1.4.101 (executor 1) (1/1)
2026-01-16 16:41:15.364 | 26/01/16 22:41:15 INFO TaskSchedulerImpl: Removed TaskSet 41.0 whose tasks have all completed, from pool 
2026-01-16 16:41:15.365 | 26/01/16 22:41:15 INFO DAGScheduler: ResultStage 41 (collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87) finished in 27 ms
2026-01-16 16:41:15.365 | 26/01/16 22:41:15 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2026-01-16 16:41:15.365 | 26/01/16 22:41:15 INFO TaskSchedulerImpl: Canceling stage 41
2026-01-16 16:41:15.365 | 26/01/16 22:41:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
2026-01-16 16:41:15.365 | 26/01/16 22:41:15 INFO DAGScheduler: Job 27 finished: collect at /app/.worktrees/cb765b53431b91673a87979141da9b1227bd705e/k3s/spark/preprocessing/preprocessing_001.py:87, took 29.147338 ms
2026-01-16 16:41:15.650 | 2026-01-16 22:41:15,649 - SparkPreprocessing - ERROR - Failed saving model to S3
2026-01-16 16:41:15.650 | Traceback (most recent call last):
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 133, in _save_scaler_artifact
2026-01-16 16:41:15.650 |     self.s3.upload_file(
2026-01-16 16:41:15.650 |     ^^^^^^^^^^^^^^^^^^^
2026-01-16 16:41:15.650 | AttributeError: 'NoneType' object has no attribute 'upload_file'
2026-01-16 16:41:15.650 | 2026-01-16 22:41:15,649 - SparkPreprocessing - ERROR - Preprocess failed to complete: 'NoneType' object has no attribute 'upload_file'
2026-01-16 16:41:15.650 | Traceback (most recent call last):
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 110, in preprocess
2026-01-16 16:41:15.650 |     self._save_scaler_artifact()
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 133, in _save_scaler_artifact
2026-01-16 16:41:15.650 |     self.s3.upload_file(
2026-01-16 16:41:15.650 |     ^^^^^^^^^^^^^^^^^^^
2026-01-16 16:41:15.650 | AttributeError: 'NoneType' object has no attribute 'upload_file'
2026-01-16 16:41:15.650 | Traceback (most recent call last):
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 237, in <module>
2026-01-16 16:41:15.650 |     main()
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 226, in main
2026-01-16 16:41:15.650 |     preprocessing.preprocess('train')
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 110, in preprocess
2026-01-16 16:41:15.650 |     self._save_scaler_artifact()
2026-01-16 16:41:15.650 |   File "/app/repo/k3s/spark/main.py", line 133, in _save_scaler_artifact
2026-01-16 16:41:15.650 |     self.s3.upload_file(
2026-01-16 16:41:15.650 |     ^^^^^^^^^^^^^^^^^^^
2026-01-16 16:41:15.650 | AttributeError: 'NoneType' object has no attribute 'upload_file'
2026-01-16 16:41:15.763 | 26/01/16 22:41:15 INFO SparkContext: SparkContext is stopping with exitCode 0 from stop at SparkSubmit.scala:1036.
2026-01-16 16:41:15.771 | 26/01/16 22:41:15 INFO SparkUI: Stopped Spark web UI at http://spark-app-0-driver-svc.spark.svc:4040
2026-01-16 16:41:15.772 | 26/01/16 22:41:15 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
2026-01-16 16:41:15.772 | 26/01/16 22:41:15 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
2026-01-16 16:41:15.779 | 26/01/16 22:41:15 INFO ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
2026-01-16 16:41:15.918 | 26/01/16 22:41:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2026-01-16 16:41:15.934 | 26/01/16 22:41:15 INFO MemoryStore: MemoryStore cleared
2026-01-16 16:41:15.934 | 26/01/16 22:41:15 INFO BlockManager: BlockManager stopped
2026-01-16 16:41:15.937 | 26/01/16 22:41:15 INFO BlockManagerMaster: BlockManagerMaster stopped
2026-01-16 16:41:15.941 | 26/01/16 22:41:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2026-01-16 16:41:15.967 | 26/01/16 22:41:15 INFO SparkContext: Successfully stopped SparkContext
2026-01-16 16:41:15.969 | 26/01/16 22:41:15 INFO ShutdownHookManager: Shutdown hook called
2026-01-16 16:41:15.969 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-f1a1ae2e-a917-4bd5-91e6-792f33696aee
2026-01-16 16:41:15.973 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/localPyFiles-3dfc3011-7b7a-41a9-b383-7151e26c5967
2026-01-16 16:41:15.976 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-a2a82d69-df5d-4067-b5ec-122bedf41902
2026-01-16 16:41:15.981 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /var/data/spark-5e15ccd3-1786-4cf2-8a2a-c880f839b9bd/spark-a7b48932-1c69-4115-8a77-1a96be472682
2026-01-16 16:41:15.983 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c861eb5-7898-4e96-a18a-7d28df881507
2026-01-16 16:41:15.986 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-efb3e856-5695-4577-bb53-3925d6355236
2026-01-16 16:41:15.990 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /tmp/artifacts-5fde58c6-7586-4103-a9e1-e0ab4624a1b3
2026-01-16 16:41:15.993 | 26/01/16 22:41:15 INFO ShutdownHookManager: Deleting directory /var/data/spark-5e15ccd3-1786-4cf2-8a2a-c880f839b9bd/spark-a7b48932-1c69-4115-8a77-1a96be472682/pyspark-8295025a-12f3-4382-8bd0-7178e309c333
2026-01-16 16:41:16.001 | 26/01/16 22:41:16 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
2026-01-16 16:41:16.001 | 26/01/16 22:41:16 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
2026-01-16 16:41:16.001 | 26/01/16 22:41:16 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.